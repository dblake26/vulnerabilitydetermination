{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homeless Vulnerability Determination Using Machine Learning\n",
    "\n",
    "## Author: Desiree Blake, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep Data for Machine Learning by One Hot Encoding Categorical Values and Label Encoding the Binary Values. \n",
    "\n",
    "Produce an output to show mappings between encoded values and their original categories for each of the One Hot Encoded and Label Encoded Columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['Client ID', 'Relation To HoH', 'Family Size', 'Age', 'Race', 'Gender', 'Veteran Status', 'Health Insurance', 'Disabling Condition', 'Physical Disability', 'Developmental Disability', 'Chronic Illness', 'Mental Illness', 'Substance Use', 'HIV Status', 'Domestic Violence', 'Exit Destination', 'Chronically Homeless', 'Original Vulnerability Factors Count', 'Original Target Variable', 'Updated Vulnerability Factors Count', 'Updated Target Variable']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_updated.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print the column names to verify\n",
    "print(\"Column names:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a Baseline Model Using Random Forrest Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: Index(['Client ID', 'Relation To HoH', 'Family Size', 'Age', 'Race', 'Gender',\n",
      "       'Veteran Status', 'Health Insurance', 'Disabling Condition',\n",
      "       'Physical Disability', 'Developmental Disability', 'Chronic Illness',\n",
      "       'Mental Illness', 'Substance Use', 'HIV Status', 'Domestic Violence',\n",
      "       'Exit Destination', 'Chronically Homeless',\n",
      "       'Original Vulnerability Factors Count', 'Original Target Variable',\n",
      "       'Updated Vulnerability Factors Count', 'Updated Target Variable',\n",
      "       'Vulnerability Factors Count', 'Target Variable'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check the columns of the DataFrame to ensure \"Target Variable\" exists\n",
    "print(\"Columns in DataFrame:\", df.columns)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (2834, 66), indices imply (2834, 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 96\u001b[0m\n\u001b[0;32m     93\u001b[0m df, label_encoders \u001b[38;5;241m=\u001b[39m label_encode_columns(df, binary_columns)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# One-hot encode categorical columns\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m data_transformed_df, column_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mone_hot_encode_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Get the feature names after transformation\u001b[39;00m\n\u001b[0;32m     99\u001b[0m onehot_feature_names \u001b[38;5;241m=\u001b[39m column_transformer\u001b[38;5;241m.\u001b[39mnamed_transformers_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget_feature_names_out(categorical_columns)\n",
      "Cell \u001b[1;32mIn[48], line 41\u001b[0m, in \u001b[0;36mone_hot_encode_columns\u001b[1;34m(df, categorical_columns)\u001b[0m\n\u001b[0;32m     39\u001b[0m data_transformed \u001b[38;5;241m=\u001b[39m column_transformer\u001b[38;5;241m.\u001b[39mfit_transform(df)\n\u001b[0;32m     40\u001b[0m onehot_feature_names \u001b[38;5;241m=\u001b[39m column_transformer\u001b[38;5;241m.\u001b[39mnamed_transformers_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget_feature_names_out(categorical_columns)\n\u001b[1;32m---> 41\u001b[0m data_transformed_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monehot_feature_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data_transformed_df, column_transformer\n",
      "File \u001b[1;32mc:\\Users\\desir\\vulnerabilitydetermination\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    825\u001b[0m         )\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mc:\\Users\\desir\\vulnerabilitydetermination\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\desir\\vulnerabilitydetermination\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (2834, 66), indices imply (2834, 34)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_updated.csv\"\n",
    "\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def replace_unknowns(df, cols_to_replace, replace_dict):\n",
    "    for col in cols_to_replace:\n",
    "        df[col] = df[col].str.strip().str.lower().replace(replace_dict)\n",
    "    return df\n",
    "\n",
    "def impute_missing_values(df, numeric_features):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    df[numeric_features] = imputer.fit_transform(df[numeric_features])\n",
    "    return df\n",
    "\n",
    "def fill_na_categorical(df, categorical_columns):\n",
    "    df[categorical_columns] = df[categorical_columns].fillna('Unknown')\n",
    "    return df\n",
    "\n",
    "def label_encode_columns(df, binary_columns):\n",
    "    label_encoders = {}\n",
    "    for column in binary_columns:\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[column + '_encoded'] = label_encoder.fit_transform(df[column].fillna('Unknown'))\n",
    "        label_encoders[column] = label_encoder\n",
    "    return df, label_encoders\n",
    "\n",
    "def one_hot_encode_columns(df, categorical_columns):\n",
    "    column_transformer = ColumnTransformer(\n",
    "        transformers=[('cat', OneHotEncoder(drop='first'), categorical_columns)],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    data_transformed = column_transformer.fit_transform(df)\n",
    "    onehot_feature_names = column_transformer.named_transformers_['cat'].get_feature_names_out(categorical_columns)\n",
    "    data_transformed_df = pd.DataFrame(data_transformed, columns=onehot_feature_names)\n",
    "    return data_transformed_df, column_transformer\n",
    "\n",
    "def combine_encoded_columns(data_transformed_df, df, encoded_columns):\n",
    "    df_encoded = pd.concat([data_transformed_df, df[encoded_columns].reset_index(drop=True)], axis=1)\n",
    "    df_encoded.columns = df_encoded.columns.astype(str)\n",
    "    return df_encoded\n",
    "\n",
    "# Load the dataset\n",
    "df = load_data(file_path)\n",
    "\n",
    "# Mapping of conditions to replace with 'unknown'\n",
    "replace_dict = {\n",
    "    '': 'Unknown',\n",
    "    \"client doesn't know\": 'Unknown',\n",
    "    'data not collected': 'Unknown',\n",
    "    'client prefers not to answer': 'Unknown',\n",
    "    \"don't know/refused\": 'Unknown'\n",
    "}\n",
    "\n",
    "# List of columns to replace values in\n",
    "cols_to_replace = ['Health Insurance', 'Disabling Condition', 'Physical Disability',\n",
    "                   'Developmental Disability', 'Chronic Illness', 'Mental Illness',\n",
    "                   'Substance Use', 'HIV Status', 'Domestic Violence', 'Chronically Homeless']\n",
    "\n",
    "# Replace specified conditions with 'unknown' in specified columns\n",
    "df = replace_unknowns(df, cols_to_replace, replace_dict)\n",
    "\n",
    "# Impute missing values for numerical columns if any\n",
    "numeric_features = ['Age', 'Family Size']\n",
    "df = impute_missing_values(df, numeric_features)\n",
    "\n",
    "# Replace NaN values with 'Unknown' in categorical columns\n",
    "categorical_columns = ['Race', 'Gender', 'Exit Destination']\n",
    "df = fill_na_categorical(df, categorical_columns)\n",
    "\n",
    "# Columns that need label encoding (with exact column names)\n",
    "binary_columns = [\n",
    "    'Veteran Status', \n",
    "    'Health Insurance', \n",
    "    'Disabling Condition', \n",
    "    'Physical Disability', \n",
    "    'Developmental Disability', \n",
    "    'Chronic Illness', \n",
    "    'Mental Illness', \n",
    "    'Substance Use', \n",
    "    'HIV Status', \n",
    "    'Domestic Violence', \n",
    "    'Chronically Homeless'\n",
    "]\n",
    "\n",
    "# Label encode binary columns\n",
    "df, label_encoders = label_encode_columns(df, binary_columns)\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "data_transformed_df, column_transformer = one_hot_encode_columns(df, categorical_columns)\n",
    "\n",
    "# Get the feature names after transformation\n",
    "onehot_feature_names = column_transformer.named_transformers_['cat'].get_feature_names_out(categorical_columns)\n",
    "encoded_columns = [col + '_encoded' for col in binary_columns]\n",
    "\n",
    "# Combine one-hot encoded columns with the rest of the data\n",
    "df_encoded = combine_encoded_columns(data_transformed_df, df, encoded_columns)\n",
    "\n",
    "# Ensure all column names are strings\n",
    "df_encoded.columns = df_encoded.columns.astype(str)\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpdated Target Variable\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist in the DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Define features and target variable\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf_encoded\u001b[49m\n\u001b[0;32m     12\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpdated Target Variable\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Split data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Check if 'Updated Target Variable' exists in the DataFrame\n",
    "if 'Updated Target Variable' not in df.columns:\n",
    "    raise KeyError(\"The column 'Updated Target Variable' does not exist in the DataFrame\")\n",
    "\n",
    "# Define features and target variable\n",
    "X = df_encoded\n",
    "y = df['Updated Target Variable']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "try:\n",
    "    model.fit(X_train, y_train)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while training the model: {e}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print classification report and accuracy\n",
    "print(\"Random Forest Model\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "column_key_label_encoded = {\n",
    "    'Veteran Status_encoded': 'Served in U.S. Military (Yes/No)',\n",
    "    'Health Insurance_encoded': 'Had insurance at program entry (Yes/No)',\n",
    "    'Disabling Condition_encoded': 'Has disability condition (Yes/No)',\n",
    "    'Physical Disability_encoded': 'Has impacting physical disability (Yes/No)',\n",
    "    'Developmental Disability_encoded': 'Has impacting developmental disability (Yes/No)',\n",
    "    'Chronic Illness_encoded': 'Has impacting chronic illness (Yes/No)',\n",
    "    'Mental Illness_encoded': 'Has impacting mental illness (Yes/No)',\n",
    "    'Substance Use_encoded': 'Participates in impacting substance use (Yes/No)',\n",
    "    'HIV Status_encoded': 'Has HIV/AIDS (Yes/No)',\n",
    "    'Domestic Violence_encoded': 'History of domestic violence',\n",
    "    'Chronically Homeless_encoded': 'Homeless for extended period (Yes/No)'\n",
    "}\n",
    "\n",
    "print(\"Label Encoded Columns:\")\n",
    "for column in df.columns:\n",
    "    if column.endswith('_encoded') and column in column_key_label_encoded:\n",
    "        print(f\"{column}: {column_key_label_encoded[column]}\")\n",
    "        original_column = column.split('_encoded')[0]\n",
    "        label_encoder = label_encoders[original_column]\n",
    "        if label_encoder:\n",
    "            for label, original_value in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)):\n",
    "                print(f\"Encoded value {original_value} corresponds to {label}\")\n",
    "        print()\n",
    "\n",
    "print(\"\\nOne-Hot Encoded Columns:\")\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    categories = column_transformer.named_transformers_['cat'].categories_[i]\n",
    "    print(f\"{column}:\")\n",
    "    for j, category in enumerate(categories):\n",
    "        print(f\"Encoded value {j} corresponds to {category}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
