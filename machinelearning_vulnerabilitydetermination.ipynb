{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homeless Vulnerability Determination Using Machine Learning\n",
    "\n",
    "### Author: Desiree Blake, 2024\n",
    "\n",
    "#### This Jupyter notebook presents the methodology and results for a machine learning project aimed at determining and prioritizing the vulnerability of individuals in a homelessness dataset. The goal is to develop a predictive model that ranks clients based on their likelihood of being highly vulnerable, which helps in identifying those who are in most need of assistance. Outputs for this notebook can be found in the ranked_clients.csv and filtered_ranked_clients.csv files in the Homeless Vulnerability Github Repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prep Data by Combining Data Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Client ID Relation To HoH  Family Size   Age     Race           Gender  \\\n",
      "0     723151            Self            1  40.0    Black      Cisgendered   \n",
      "1     721310            Self            1  32.0    Black  Non-Cisgendered   \n",
      "2     721408            Self            1  36.0    Black      Cisgendered   \n",
      "3     721493            Self            3  30.0    Black      Cisgendered   \n",
      "4     720468            Self            1  51.0  Unknown          Unknown   \n",
      "\n",
      "  Veteran Status Health Insurance Disabling Condition Physical Disability  \\\n",
      "0             No               No                 Yes                 Yes   \n",
      "1             No              Yes                 Yes                 Yes   \n",
      "2             No              Yes                 Yes                  No   \n",
      "3             No               No                  No                  No   \n",
      "4             No              NaN                 Yes                 NaN   \n",
      "\n",
      "   ... Domestic Violence                              Exit Destination_x  \\\n",
      "0  ...               Yes                     No exit interview completed   \n",
      "1  ...               Yes                     No exit interview completed   \n",
      "2  ...               Yes                     No exit interview completed   \n",
      "3  ...               Yes  Rental by client, with ongoing housing subsidy   \n",
      "4  ...               NaN                     No exit interview completed   \n",
      "\n",
      "  Chronically Homeless Original Vulnerability Factors Count  \\\n",
      "0                   No                                    5   \n",
      "1                  Yes                                    7   \n",
      "2                   No                                    5   \n",
      "3                   No                                    3   \n",
      "4                  Yes                                    4   \n",
      "\n",
      "  Original Target Variable Updated Vulnerability Factors Count  \\\n",
      "0                        1                                   5   \n",
      "1                        1                                   7   \n",
      "2                        1                                   5   \n",
      "3                        2                                   3   \n",
      "4                        2                                   4   \n",
      "\n",
      "  Updated Target Variable Vulnerability Factors Count  Target Variable  \\\n",
      "0                       2                           5                1   \n",
      "1                       1                           7                1   \n",
      "2                       2                           5                1   \n",
      "3                       0                           3                2   \n",
      "4                       2                           4                2   \n",
      "\n",
      "                               Exit Destination_y  \n",
      "0                     No exit interview completed  \n",
      "1                     No exit interview completed  \n",
      "2                     No exit interview completed  \n",
      "3  Rental by client, with ongoing housing subsidy  \n",
      "4                     No exit interview completed  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Client ID Relation To HoH  Family Size   Age     Race           Gender  \\\n",
      "0     723151            Self            1  40.0    Black      Cisgendered   \n",
      "1     721310            Self            1  32.0    Black  Non-Cisgendered   \n",
      "2     721408            Self            1  36.0    Black      Cisgendered   \n",
      "3     721493            Self            3  30.0    Black      Cisgendered   \n",
      "4     720468            Self            1  51.0  Unknown          Unknown   \n",
      "\n",
      "  Veteran Status Health Insurance Disabling Condition Physical Disability  \\\n",
      "0             No               No                 Yes                 Yes   \n",
      "1             No              Yes                 Yes                 Yes   \n",
      "2             No              Yes                 Yes                  No   \n",
      "3             No               No                  No                  No   \n",
      "4             No              NaN                 Yes                 NaN   \n",
      "\n",
      "   ... Domestic Violence                       Original Exit Destination  \\\n",
      "0  ...               Yes                     No exit interview completed   \n",
      "1  ...               Yes                     No exit interview completed   \n",
      "2  ...               Yes                     No exit interview completed   \n",
      "3  ...               Yes  Rental by client, with ongoing housing subsidy   \n",
      "4  ...               NaN                     No exit interview completed   \n",
      "\n",
      "  Chronically Homeless Original Vulnerability Factors Count  \\\n",
      "0                   No                                    5   \n",
      "1                  Yes                                    7   \n",
      "2                   No                                    5   \n",
      "3                   No                                    3   \n",
      "4                  Yes                                    4   \n",
      "\n",
      "  Original Target Variable Updated Vulnerability Factors Count  \\\n",
      "0                        1                                   5   \n",
      "1                        1                                   7   \n",
      "2                        1                                   5   \n",
      "3                        2                                   3   \n",
      "4                        2                                   4   \n",
      "\n",
      "  Updated Target Variable Vulnerability Factors Count  Target Variable  \\\n",
      "0                       2                           5                1   \n",
      "1                       1                           7                1   \n",
      "2                       2                           5                1   \n",
      "3                       0                           3                2   \n",
      "4                       2                           4                2   \n",
      "\n",
      "                  Exit Destination Classification  \n",
      "0                     No exit interview completed  \n",
      "1                     No exit interview completed  \n",
      "2                     No exit interview completed  \n",
      "3  Rental by client, with ongoing housing subsidy  \n",
      "4                     No exit interview completed  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df_exit_destination = pd.read_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR.csv\")\n",
    "df_target_variables = pd.read_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_updated.csv\")\n",
    "\n",
    "# Merge the datasets on 'Client ID' (or another common column)\n",
    "df_combined = pd.merge(df_target_variables, df_exit_destination[['Client ID', 'Exit Destination']], on='Client ID', how='left')\n",
    "\n",
    "df_combined.to_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\", index=False)\n",
    "\n",
    "# Check the first few rows to verify the merge\n",
    "print(df_combined.head())\n",
    "\n",
    "# Rename the columns to remove suffixes\n",
    "df_combined.rename(columns={\n",
    "    'Exit Destination_x': 'Original Exit Destination',\n",
    "    'Exit Destination_y': 'Exit Destination Classification'\n",
    "}, inplace=True)\n",
    "\n",
    "# Ensure columns have been renamed correctly \n",
    "print(df_combined.head())\n",
    "\n",
    "# Save the Updated DF\n",
    "df_combined.to_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['Client ID', 'Relation To HoH', 'Family Size', 'Age', 'Race', 'Gender', 'Veteran Status', 'Health Insurance', 'Disabling Condition', 'Physical Disability', 'Developmental Disability', 'Chronic Illness', 'Mental Illness', 'Substance Use', 'HIV Status', 'Domestic Violence', 'Original Exit Destination', 'Chronically Homeless', 'Original Vulnerability Factors Count', 'Original Target Variable', 'Updated Vulnerability Factors Count', 'Updated Target Variable', 'Vulnerability Factors Count', 'Target Variable', 'Exit Destination Classification']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print the column names to verify\n",
    "print(\"Column names:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: Index(['Client ID', 'Relation To HoH', 'Family Size', 'Age', 'Race', 'Gender',\n",
      "       'Veteran Status', 'Health Insurance', 'Disabling Condition',\n",
      "       'Physical Disability', 'Developmental Disability', 'Chronic Illness',\n",
      "       'Mental Illness', 'Substance Use', 'HIV Status', 'Domestic Violence',\n",
      "       'Original Exit Destination', 'Chronically Homeless',\n",
      "       'Original Vulnerability Factors Count', 'Original Target Variable',\n",
      "       'Updated Vulnerability Factors Count', 'Updated Target Variable',\n",
      "       'Vulnerability Factors Count', 'Target Variable',\n",
      "       'Exit Destination Classification'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check the columns of the DataFrame to ensure \"Target Variable\" exists\n",
    "print(\"Columns in DataFrame:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Develop a Baseline Model Using Random Forrest Tree\n",
    "\n",
    "- Prep Data for Machine Learning by One Hot Encoding Categorical Values and Label Encoding the Binary Values. \n",
    "\n",
    "- Produce an output to show mappings between encoded values and their original categories for each of the One Hot Encoded and Label Encoded Columns\n",
    "\n",
    "- Provide Model Performance Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " Client ID                                                                                                            0\n",
      "Family Size                                                                                                          0\n",
      "Age                                                                                                                  0\n",
      "Race                                                                                                                 0\n",
      "Gender                                                                                                               0\n",
      "                                                                                                                    ..\n",
      "Exit Destination Classification_Staying or living with family, temporary tenure (e.g., room, apartment or house)     0\n",
      "Exit Destination Classification_Staying or living with friends, permanent tenure                                     0\n",
      "Exit Destination Classification_Staying or living with friends, temporary tenure (e.g., room, apartment or house)    0\n",
      "Exit Destination Classification_Substance abuse treatment facility or detox center                                   0\n",
      "Exit Destination Classification_Transitional housing for homeless persons (including homeless youth)                 0\n",
      "Length: 67, dtype: int64\n",
      "Feature Data Types Before Splitting:\n",
      " Client ID                                                                                                              int64\n",
      "Family Size                                                                                                            int64\n",
      "Age                                                                                                                  float64\n",
      "Race                                                                                                                 float64\n",
      "Gender                                                                                                               float64\n",
      "                                                                                                                      ...   \n",
      "Exit Destination Classification_Staying or living with family, temporary tenure (e.g., room, apartment or house)       int64\n",
      "Exit Destination Classification_Staying or living with friends, permanent tenure                                       int64\n",
      "Exit Destination Classification_Staying or living with friends, temporary tenure (e.g., room, apartment or house)      int64\n",
      "Exit Destination Classification_Substance abuse treatment facility or detox center                                     int64\n",
      "Exit Destination Classification_Transitional housing for homeless persons (including homeless youth)                   int64\n",
      "Length: 67, dtype: object\n",
      "Target Variable Data Type:\n",
      " int64\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       302\n",
      "           1       1.00      1.00      1.00        96\n",
      "           2       1.00      1.00      1.00       453\n",
      "\n",
      "    accuracy                           1.00       851\n",
      "   macro avg       1.00      1.00      1.00       851\n",
      "weighted avg       1.00      1.00      1.00       851\n",
      "\n",
      "Feature Importances:\n",
      "                                               Feature  Importance\n",
      "16               Original Vulnerability Factors Count    0.418243\n",
      "18                Updated Vulnerability Factors Count    0.349605\n",
      "17                           Original Target Variable    0.054152\n",
      "15                               Chronically Homeless    0.042804\n",
      "7                                 Disabling Condition    0.024679\n",
      "..                                                ...         ...\n",
      "3                                                Race    0.000000\n",
      "20      Original Exit Destination_Client doesn't know    0.000000\n",
      "41  Original Exit Destination_Substance abuse trea...    0.000000\n",
      "44  Exit Destination Classification_Client doesn't...    0.000000\n",
      "54  Exit Destination Classification_Owned by clien...    0.000000\n",
      "\n",
      "[67 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the updated dataset\n",
    "df_combined = pd.read_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\")\n",
    "\n",
    "# Remove the 'Relation To HoH' column\n",
    "df_combined = df_combined.drop(columns=['Relation To HoH'])\n",
    "df_combined = df_combined.drop(columns=['Target Variable'])\n",
    "df_combined = df_combined.drop(columns=['Vulnerability Factors Count'])\n",
    "\n",
    "# Define binary columns for label encoding\n",
    "binary_columns = [\n",
    "    'Veteran Status', \n",
    "    'Health Insurance', \n",
    "    'Disabling Condition', \n",
    "    'Physical Disability', \n",
    "    'Developmental Disability', \n",
    "    'Chronic Illness', \n",
    "    'Mental Illness', \n",
    "    'Substance Use', \n",
    "    'HIV Status', \n",
    "    'Domestic Violence', \n",
    "    'Chronically Homeless'\n",
    "]\n",
    "\n",
    "# Initialize LabelEncoder for binary columns\n",
    "label_encoders = {}\n",
    "for column in binary_columns:\n",
    "    le = LabelEncoder()\n",
    "    # Make a copy before modifying\n",
    "    df_combined[column] = df_combined[column].copy()\n",
    "    df_combined[column] = le.fit_transform(df_combined[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define categorical columns for one-hot encoding\n",
    "categorical_columns = [\n",
    "    'Original Exit Destination', \n",
    "    'Exit Destination Classification'\n",
    "]\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "# Make a copy before modifying\n",
    "df_combined = df_combined.copy()\n",
    "df_combined = pd.get_dummies(df_combined, columns=categorical_columns)\n",
    "\n",
    "# Numerical columns do not need encoding\n",
    "numerical_columns = [\n",
    "    'Original Vulnerability Factors Count',\n",
    "    'Original Target Variable',\n",
    "    'Updated Vulnerability Factors Count',\n",
    "    'Updated Target Variable',\n",
    "    'Vulnerability Factors Count'\n",
    "]\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Updated Target Variable'\n",
    "\n",
    "# Define features and target\n",
    "feature_columns = [col for col in df_combined.columns if col != target_column]\n",
    "\n",
    "# Make a copy of the DataFrame to avoid modifying the original one\n",
    "X = df_combined[feature_columns].copy()\n",
    "y = df_combined[target_column].copy()\n",
    "\n",
    "# Convert boolean columns to integers\n",
    "boolean_columns = X.select_dtypes(include=['bool']).columns\n",
    "for column in boolean_columns:\n",
    "    X[column] = X[column].astype(int)\n",
    "\n",
    "# Convert all columns to numeric\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle missing values\n",
    "X.fillna(0, inplace=True)  # Or use another method to handle missing values\n",
    "\n",
    "# Additional checks\n",
    "print(\"Missing values:\\n\", X.isnull().sum())\n",
    "print(\"Feature Data Types Before Splitting:\\n\", X.dtypes)\n",
    "print(\"Target Variable Data Type:\\n\", y.dtypes)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Optional - Feature importance\n",
    "importances = rf_classifier.feature_importances_\n",
    "feature_importances = pd.DataFrame({'Feature': feature_columns, 'Importance': importances})\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "print(\"Feature Importances:\\n\", feature_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "The model achieved an impressive **accuracy of 1.0**, indicating perfect performance on the test dataset. The classification report demonstrates the model's ability to correctly predict each class:\n",
    "\n",
    "- **Class 0**: Precision, recall, and F1-score are all 1.00, with 302 instances correctly classified.\n",
    "- **Class 1**: Precision, recall, and F1-score are all 1.00, with 96 instances correctly classified.\n",
    "- **Class 2**: Precision, recall, and F1-score are all 1.00, with 453 instances correctly classified.\n",
    "\n",
    "The **macro average** and **weighted average** metrics are also 1.00, highlighting consistent performance across different classes.\n",
    "\n",
    "**Accuracy**: 1.0\n",
    "\n",
    "**Classification Report:**\n",
    "\n",
    "| Class | Precision | Recall | F1-Score | Support |\n",
    "|-------|-----------|--------|----------|---------|\n",
    "| 0     | 1.00      | 1.00   | 1.00     | 302     |\n",
    "| 1     | 1.00      | 1.00   | 1.00     | 96      |\n",
    "| 2     | 1.00      | 1.00   | 1.00     | 453     |\n",
    "| **Accuracy** |       | 1.00   |          | 851     |\n",
    "| **Macro Avg** | 1.00  | 1.00   | 1.00     | 851     |\n",
    "| **Weighted Avg** | 1.00 | 1.00   | 1.00     | 851     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "The table below shows the importance of each feature in the model:\n",
    "\n",
    "- **Original Vulnerability Factors Count**: The most influential feature with an importance score of 0.418243, suggesting it plays a significant role in predicting vulnerability.\n",
    "- **Updated Vulnerability Factors Count**: Also highly important with a score of 0.349605, indicating its strong influence on the model’s predictions.\n",
    "- **Original Target Variable**: Contributes moderately with an importance score of 0.054152.\n",
    "- **Chronically Homeless**: Has a lower importance score of 0.042804, but still contributes to the model’s decisions.\n",
    "- **Disabling Condition**: The least important among the listed features with a score of 0.024679.\n",
    "\n",
    "These scores provide insight into which features are most critical for determining vulnerability in the dataset.\n",
    "\n",
    "\n",
    "| Feature                           | Importance |\n",
    "|-----------------------------------|------------|\n",
    "| Original Vulnerability Factors Count | 0.418243   |\n",
    "| Updated Vulnerability Factors Count  | 0.349605   |\n",
    "| Original Target Variable             | 0.054152   |\n",
    "| Chronically Homeless                 | 0.042804   |\n",
    "| Disabling Condition                  | 0.024679   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prioritize (Rank) Clients based on their Predicted Vulnerability Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few Client IDs:\n",
      " 0    723151\n",
      "1    721310\n",
      "2    721408\n",
      "3    721493\n",
      "4    720468\n",
      "5    631503\n",
      "6    627234\n",
      "7    610441\n",
      "8    719317\n",
      "9    716657\n",
      "Name: Client ID, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Ensure Client IDs maintain intact for the ranked output \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file ensuring Client ID is read as a string\n",
    "df = pd.read_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\", dtype={'Client ID': str})\n",
    "\n",
    "# Convert Client ID to string (in case it was misread)\n",
    "df['Client ID'] = df['Client ID'].astype(str)\n",
    "\n",
    "# Check the first few entries to ensure they are correctly formatted\n",
    "print(\"First few Client IDs:\\n\", df['Client ID'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Prob_Class_0  Prob_Class_1  Prob_Class_2 Client ID  True_Label  \\\n",
      "600           0.0          1.00          0.00    723008           1   \n",
      "171           0.0          1.00          0.00    681041           1   \n",
      "67            0.0          1.00          0.00    544579           1   \n",
      "433           0.0          1.00          0.00    522405           1   \n",
      "807           0.0          0.99          0.01    538630           1   \n",
      "\n",
      "     Vulnerability_Score  \n",
      "600                 1.00  \n",
      "171                 1.00  \n",
      "67                  1.00  \n",
      "433                 1.00  \n",
      "807                 0.99  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the original dataset to get Client IDs\n",
    "df = pd.read_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\", dtype={'Client ID': str})\n",
    "\n",
    "# Preprocess data as before\n",
    "# Assuming X_train, X_test, y_train, y_test are already prepared\n",
    "\n",
    "# Add Client IDs to X_test\n",
    "X_test_with_ids = X_test.copy()\n",
    "X_test_with_ids['Client ID'] = df.loc[X_test.index, 'Client ID']\n",
    "\n",
    "# Predict probabilities for each class\n",
    "probabilities = rf_classifier.predict_proba(X_test)\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "prob_df = pd.DataFrame(probabilities, columns=[f'Prob_Class_{i}' for i in range(probabilities.shape[1])])\n",
    "\n",
    "# Add Client IDs and target variable to the DataFrame\n",
    "prob_df['Client ID'] = X_test_with_ids['Client ID'].values\n",
    "prob_df['True_Label'] = y_test.values\n",
    "\n",
    "# Use probability of class 1 (Highly Vulnerable) for the vulnerability score\n",
    "prob_df['Vulnerability_Score'] = prob_df[f'Prob_Class_1']\n",
    "\n",
    "# Rank Client IDs based on the vulnerability score (highly vulnerable clients at the top)\n",
    "ranked_clients = prob_df.sort_values(by='Vulnerability_Score', ascending=False)\n",
    "\n",
    "# Save the ranked clients to a CSV file\n",
    "ranked_clients.to_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\ranked_clients.csv\", index=False)\n",
    "\n",
    "# Print first few rows to check the result\n",
    "print(ranked_clients.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Predicted Probabilities Output Columns\n",
    "####  View Full Predicited Probabilities Ranking Output in ranked_clients.csv file.\n",
    "\n",
    "| Column Name             | Description                                                         |\n",
    "|--------------------------|---------------------------------------------------------------------|\n",
    "| `Prob_Class_0`           | Probability of the client being classified as Class 0 (Less Vulnerable). |\n",
    "| `Prob_Class_1`           | Probability of the client being classified as Class 1 (Highly Vulnerable). |\n",
    "| `Prob_Class_2`           | Probability of the client being classified as Class 2 (Moderately Vulnerable). |\n",
    "| `Client ID`              | Unique identifier for the client. Represents the client’s ID from the dataset. |\n",
    "| `True_Label`             | Actual label of the client, indicating their true class.            |\n",
    "| `Vulnerability_Score`    | Calculated score based on the probability of being in Class 1 (Highly Vulnerable). Clients with higher scores are ranked as more vulnerable. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Filter out clients without an exit destination for more focused prioritization. \n",
    "####  View Full Predicited Probabilities Ranking Output in filtered_ranked_clients.csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Prob_Class_0  Prob_Class_1  Prob_Class_2 Client ID  True_Label  \\\n",
      "20           0.0          0.98          0.02    734308           1   \n",
      "24           0.0          0.97          0.03    538169           1   \n",
      "25           0.0          0.97          0.03    725757           1   \n",
      "29           0.0          0.97          0.03    526230           1   \n",
      "30           0.0          0.97          0.03    575911           1   \n",
      "\n",
      "    Vulnerability_Score Original Exit Destination  \n",
      "20                 0.98                       NaN  \n",
      "24                 0.97                       NaN  \n",
      "25                 0.97                       NaN  \n",
      "29                 0.97                       NaN  \n",
      "30                 0.97                       NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the original dataset to get Client IDs and exit destinations\n",
    "df = pd.read_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\", dtype={'Client ID': str})\n",
    "\n",
    "# Preprocess data as before\n",
    "# Assuming X_train, X_test, y_train, y_test, and rf_classifier are already prepared\n",
    "\n",
    "# Add Client IDs to X_test\n",
    "X_test_with_ids = X_test.copy()\n",
    "X_test_with_ids['Client ID'] = df.loc[X_test.index, 'Client ID']\n",
    "\n",
    "# Predict probabilities for each class\n",
    "probabilities = rf_classifier.predict_proba(X_test)\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "prob_df = pd.DataFrame(probabilities, columns=[f'Prob_Class_{i}' for i in range(probabilities.shape[1])])\n",
    "\n",
    "# Add Client IDs and target variable to the DataFrame\n",
    "prob_df['Client ID'] = X_test_with_ids['Client ID'].values\n",
    "prob_df['True_Label'] = y_test.values\n",
    "\n",
    "# Use probability of class 1 (Highly Vulnerable) for the vulnerability score\n",
    "prob_df['Vulnerability_Score'] = prob_df[f'Prob_Class_1']\n",
    "\n",
    "# Rank Client IDs based on the vulnerability score (highly vulnerable clients at the top)\n",
    "ranked_clients = prob_df.sort_values(by='Vulnerability_Score', ascending=False)\n",
    "\n",
    "# Filter out clients that have exit destinations\n",
    "# Ensure you merge with the original DataFrame to check for exit destinations\n",
    "ranked_clients_with_data = ranked_clients.merge(df[['Client ID', 'Original Exit Destination']], on='Client ID', how='left')\n",
    "filtered_ranked_clients = ranked_clients_with_data[ranked_clients_with_data['Original Exit Destination'].isna()]\n",
    "\n",
    "# Save the filtered ranked clients to a CSV file\n",
    "filtered_ranked_clients.to_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\filtered_ranked_clients.csv\", index=False)\n",
    "\n",
    "# Print first few rows to check the result\n",
    "print(filtered_ranked_clients.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
