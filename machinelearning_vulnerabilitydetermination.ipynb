{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homeless Vulnerability Determination Using Machine Learning\n",
    "\n",
    "### Author: Desiree Blake, 2024\n",
    "\n",
    "#### This Jupyter notebook presents the methodology and results for a machine learning project aimed at determining and prioritizing the vulnerability of individuals in a homelessness dataset. The goal is to develop a predictive model that ranks clients based on their likelihood of being highly vulnerable, which helps in identifying those who are in most need of assistance. Outputs for this notebook can be found in the ranked_clients.csv and filtered_ranked_clients.csv files in the Homeless Vulnerability Github Repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prep Data by Combining Data Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Client ID Relation To HoH  Family Size   Age     Race           Gender  \\\n",
      "0     723151            Self            1  40.0    Black      Cisgendered   \n",
      "1     721310            Self            1  32.0    Black  Non-Cisgendered   \n",
      "2     721408            Self            1  36.0    Black      Cisgendered   \n",
      "3     721493            Self            3  30.0    Black      Cisgendered   \n",
      "4     720468            Self            1  51.0  Unknown          Unknown   \n",
      "\n",
      "  Veteran Status Health Insurance Disabling Condition Physical Disability  \\\n",
      "0             No               No                 Yes                 Yes   \n",
      "1             No              Yes                 Yes                 Yes   \n",
      "2             No              Yes                 Yes                  No   \n",
      "3             No               No                  No                  No   \n",
      "4             No              NaN                 Yes                 NaN   \n",
      "\n",
      "   ... Domestic Violence                              Exit Destination_x  \\\n",
      "0  ...               Yes                     No exit interview completed   \n",
      "1  ...               Yes                     No exit interview completed   \n",
      "2  ...               Yes                     No exit interview completed   \n",
      "3  ...               Yes  Rental by client, with ongoing housing subsidy   \n",
      "4  ...               NaN                     No exit interview completed   \n",
      "\n",
      "  Chronically Homeless Original Vulnerability Factors Count  \\\n",
      "0                   No                                    5   \n",
      "1                  Yes                                    7   \n",
      "2                   No                                    5   \n",
      "3                   No                                    3   \n",
      "4                  Yes                                    4   \n",
      "\n",
      "  Original Target Variable Updated Vulnerability Factors Count  \\\n",
      "0                        1                                   5   \n",
      "1                        1                                   7   \n",
      "2                        1                                   5   \n",
      "3                        2                                   3   \n",
      "4                        2                                   4   \n",
      "\n",
      "  Updated Target Variable Vulnerability Factors Count  Target Variable  \\\n",
      "0                       2                           5                1   \n",
      "1                       1                           7                1   \n",
      "2                       2                           5                1   \n",
      "3                       0                           3                2   \n",
      "4                       2                           4                2   \n",
      "\n",
      "                               Exit Destination_y  \n",
      "0                     No exit interview completed  \n",
      "1                     No exit interview completed  \n",
      "2                     No exit interview completed  \n",
      "3  Rental by client, with ongoing housing subsidy  \n",
      "4                     No exit interview completed  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Client ID Relation To HoH  Family Size   Age     Race           Gender  \\\n",
      "0     723151            Self            1  40.0    Black      Cisgendered   \n",
      "1     721310            Self            1  32.0    Black  Non-Cisgendered   \n",
      "2     721408            Self            1  36.0    Black      Cisgendered   \n",
      "3     721493            Self            3  30.0    Black      Cisgendered   \n",
      "4     720468            Self            1  51.0  Unknown          Unknown   \n",
      "\n",
      "  Veteran Status Health Insurance Disabling Condition Physical Disability  \\\n",
      "0             No               No                 Yes                 Yes   \n",
      "1             No              Yes                 Yes                 Yes   \n",
      "2             No              Yes                 Yes                  No   \n",
      "3             No               No                  No                  No   \n",
      "4             No              NaN                 Yes                 NaN   \n",
      "\n",
      "   ... Domestic Violence                       Original Exit Destination  \\\n",
      "0  ...               Yes                     No exit interview completed   \n",
      "1  ...               Yes                     No exit interview completed   \n",
      "2  ...               Yes                     No exit interview completed   \n",
      "3  ...               Yes  Rental by client, with ongoing housing subsidy   \n",
      "4  ...               NaN                     No exit interview completed   \n",
      "\n",
      "  Chronically Homeless Original Vulnerability Factors Count  \\\n",
      "0                   No                                    5   \n",
      "1                  Yes                                    7   \n",
      "2                   No                                    5   \n",
      "3                   No                                    3   \n",
      "4                  Yes                                    4   \n",
      "\n",
      "  Original Target Variable Updated Vulnerability Factors Count  \\\n",
      "0                        1                                   5   \n",
      "1                        1                                   7   \n",
      "2                        1                                   5   \n",
      "3                        2                                   3   \n",
      "4                        2                                   4   \n",
      "\n",
      "  Updated Target Variable Vulnerability Factors Count  Target Variable  \\\n",
      "0                       2                           5                1   \n",
      "1                       1                           7                1   \n",
      "2                       2                           5                1   \n",
      "3                       0                           3                2   \n",
      "4                       2                           4                2   \n",
      "\n",
      "                  Exit Destination Classification  \n",
      "0                     No exit interview completed  \n",
      "1                     No exit interview completed  \n",
      "2                     No exit interview completed  \n",
      "3  Rental by client, with ongoing housing subsidy  \n",
      "4                     No exit interview completed  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df_exit_destination = pd.read_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR.csv\")\n",
    "df_target_variables = pd.read_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_updated.csv\")\n",
    "\n",
    "# Merge the datasets on 'Client ID' (or another common column)\n",
    "df_combined = pd.merge(df_target_variables, df_exit_destination[['Client ID', 'Exit Destination']], on='Client ID', how='left')\n",
    "\n",
    "df_combined.to_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\", index=False)\n",
    "\n",
    "# Check the first few rows to verify the merge\n",
    "print(df_combined.head())\n",
    "\n",
    "# Rename the columns to remove suffixes\n",
    "df_combined.rename(columns={\n",
    "    'Exit Destination_x': 'Original Exit Destination',\n",
    "    'Exit Destination_y': 'Exit Destination Classification'\n",
    "}, inplace=True)\n",
    "\n",
    "# Ensure columns have been renamed correctly \n",
    "print(df_combined.head())\n",
    "\n",
    "# Save the Updated DF\n",
    "df_combined.to_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['Client ID', 'Relation To HoH', 'Family Size', 'Age', 'Race', 'Gender', 'Veteran Status', 'Health Insurance', 'Disabling Condition', 'Physical Disability', 'Developmental Disability', 'Chronic Illness', 'Mental Illness', 'Substance Use', 'HIV Status', 'Domestic Violence', 'Original Exit Destination', 'Chronically Homeless', 'Original Vulnerability Factors Count', 'Original Target Variable', 'Updated Vulnerability Factors Count', 'Updated Target Variable', 'Vulnerability Factors Count', 'Target Variable', 'Exit Destination Classification']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print the column names to verify\n",
    "print(\"Column names:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: Index(['Client ID', 'Relation To HoH', 'Family Size', 'Age', 'Race', 'Gender',\n",
      "       'Veteran Status', 'Health Insurance', 'Disabling Condition',\n",
      "       'Physical Disability', 'Developmental Disability', 'Chronic Illness',\n",
      "       'Mental Illness', 'Substance Use', 'HIV Status', 'Domestic Violence',\n",
      "       'Original Exit Destination', 'Chronically Homeless',\n",
      "       'Original Vulnerability Factors Count', 'Original Target Variable',\n",
      "       'Updated Vulnerability Factors Count', 'Updated Target Variable',\n",
      "       'Vulnerability Factors Count', 'Target Variable',\n",
      "       'Exit Destination Classification'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check the columns of the DataFrame to ensure \"Target Variable\" exists\n",
    "print(\"Columns in DataFrame:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Develop a Baseline Model Using Random Forrest Tree\n",
    "\n",
    "- Prep Data for Machine Learning by One Hot Encoding Categorical Values and Label Encoding the Binary Values. \n",
    "\n",
    "- Produce an output to show mappings between encoded values and their original categories for each of the One Hot Encoded and Label Encoded Columns\n",
    "\n",
    "- Provide Model Performance Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " Client ID                              0\n",
      "Family Size                            0\n",
      "Age                                    0\n",
      "Race                                   0\n",
      "Gender                                 0\n",
      "Veteran Status                         0\n",
      "Health Insurance                       0\n",
      "Disabling Condition                    0\n",
      "Physical Disability                    0\n",
      "Developmental Disability               0\n",
      "Chronic Illness                        0\n",
      "Mental Illness                         0\n",
      "Substance Use                          0\n",
      "HIV Status                             0\n",
      "Domestic Violence                      0\n",
      "Chronically Homeless                   0\n",
      "Updated Vulnerability Factors Count    0\n",
      "dtype: int64\n",
      "Feature Data Types Before Splitting:\n",
      " Client ID                                int64\n",
      "Family Size                              int64\n",
      "Age                                    float64\n",
      "Race                                   float64\n",
      "Gender                                 float64\n",
      "Veteran Status                           int64\n",
      "Health Insurance                         int64\n",
      "Disabling Condition                      int64\n",
      "Physical Disability                      int64\n",
      "Developmental Disability                 int64\n",
      "Chronic Illness                          int64\n",
      "Mental Illness                           int64\n",
      "Substance Use                            int64\n",
      "HIV Status                               int64\n",
      "Domestic Violence                        int64\n",
      "Chronically Homeless                     int64\n",
      "Updated Vulnerability Factors Count      int64\n",
      "dtype: object\n",
      "Target Variable Data Type:\n",
      " int64\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       302\n",
      "           1       1.00      1.00      1.00        96\n",
      "           2       1.00      1.00      1.00       453\n",
      "\n",
      "    accuracy                           1.00       851\n",
      "   macro avg       1.00      1.00      1.00       851\n",
      "weighted avg       1.00      1.00      1.00       851\n",
      "\n",
      "Feature Importances:\n",
      "                                 Feature  Importance\n",
      "16  Updated Vulnerability Factors Count    0.741586\n",
      "15                 Chronically Homeless    0.057298\n",
      "7                   Disabling Condition    0.039382\n",
      "2                                   Age    0.036189\n",
      "1                           Family Size    0.029773\n",
      "6                      Health Insurance    0.021310\n",
      "14                    Domestic Violence    0.021221\n",
      "0                             Client ID    0.018260\n",
      "12                        Substance Use    0.008678\n",
      "13                           HIV Status    0.006988\n",
      "11                       Mental Illness    0.005683\n",
      "10                      Chronic Illness    0.004600\n",
      "8                   Physical Disability    0.004592\n",
      "9              Developmental Disability    0.003017\n",
      "5                        Veteran Status    0.001425\n",
      "3                                  Race    0.000000\n",
      "4                                Gender    0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the updated dataset\n",
    "df_combined = pd.read_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\")\n",
    "\n",
    "# Remove specific columns\n",
    "df_combined = df_combined.drop(columns=['Relation To HoH', 'Target Variable', 'Vulnerability Factors Count'])\n",
    "\n",
    "# Define binary columns for label encoding\n",
    "binary_columns = [\n",
    "    'Veteran Status', \n",
    "    'Health Insurance', \n",
    "    'Disabling Condition', \n",
    "    'Physical Disability', \n",
    "    'Developmental Disability', \n",
    "    'Chronic Illness', \n",
    "    'Mental Illness', \n",
    "    'Substance Use', \n",
    "    'HIV Status', \n",
    "    'Domestic Violence', \n",
    "    'Chronically Homeless'\n",
    "]\n",
    "\n",
    "# Initialize LabelEncoder for binary columns\n",
    "label_encoders = {}\n",
    "for column in binary_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_combined[column] = df_combined[column].copy()\n",
    "    df_combined[column] = le.fit_transform(df_combined[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Remove columns related to 'Exit Destination Classification' and 'Original Exit Destination'\n",
    "exclude_columns = [\n",
    "    'Original Exit Destination', \n",
    "    'Exit Destination Classification',\n",
    "    'Original Vulnerability Factors Count',\n",
    "    'Original Target Variable'\n",
    "]\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Updated Target Variable'\n",
    "\n",
    "# Define feature columns, excluding the target column and other specified columns\n",
    "feature_columns = [col for col in df_combined.columns if col != target_column and col not in exclude_columns]\n",
    "\n",
    "# Create feature (X) and target (y) DataFrames\n",
    "X = df_combined[feature_columns].copy()\n",
    "y = df_combined[target_column].copy()\n",
    "\n",
    "# Convert boolean columns to integers\n",
    "boolean_columns = X.select_dtypes(include=['bool']).columns\n",
    "for column in boolean_columns:\n",
    "    X[column] = X[column].astype(int)\n",
    "\n",
    "# Convert all columns to numeric\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle missing values\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "# Additional checks\n",
    "print(\"Missing values:\\n\", X.isnull().sum())\n",
    "print(\"Feature Data Types Before Splitting:\\n\", X.dtypes)\n",
    "print(\"Target Variable Data Type:\\n\", y.dtypes)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Optional - Feature importance\n",
    "importances = rf_classifier.feature_importances_\n",
    "feature_importances = pd.DataFrame({'Feature': feature_columns, 'Importance': importances})\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "print(\"Feature Importances:\\n\", feature_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "The model achieved an impressive **accuracy of 1.0**, indicating perfect performance on the test dataset. The classification report demonstrates the model's ability to correctly predict each class:\n",
    "\n",
    "- **Class 0**: Precision, recall, and F1-score are all 1.00, with 302 instances correctly classified.\n",
    "- **Class 1**: Precision, recall, and F1-score are all 1.00, with 96 instances correctly classified.\n",
    "- **Class 2**: Precision, recall, and F1-score are all 1.00, with 453 instances correctly classified.\n",
    "\n",
    "The **macro average** and **weighted average** metrics are also 1.00, highlighting consistent performance across different classes.\n",
    "\n",
    "**Accuracy**: 1.0\n",
    "\n",
    "**Classification Report:**\n",
    "\n",
    "| Class | Precision | Recall | F1-Score | Support |\n",
    "|-------|-----------|--------|----------|---------|\n",
    "| 0     | 1.00      | 1.00   | 1.00     | 302     |\n",
    "| 1     | 1.00      | 1.00   | 1.00     | 96      |\n",
    "| 2     | 1.00      | 1.00   | 1.00     | 453     |\n",
    "| **Accuracy** |       | 1.00   |          | 851     |\n",
    "| **Macro Avg** | 1.00  | 1.00   | 1.00     | 851     |\n",
    "| **Weighted Avg** | 1.00 | 1.00   | 1.00     | 851     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "The table below lists the features used in the Random Forest classifier model for predicting homelessness vulnerability, along with their relative importance percentages. The importance of each feature reflects its contribution to the model's decision-making process. A higher percentage indicates a greater influence on the model's predictions.\n",
    "\n",
    "\n",
    "| Feature                                   | Importance (%) |\n",
    "|-------------------------------------------|----------------|\n",
    "| Updated Vulnerability Factors Count       | 74.1586        |\n",
    "| Chronically Homeless                      | 5.7298         |\n",
    "| Disabling Condition                       | 3.9382         |\n",
    "| Age                                       | 3.6189         |\n",
    "| Family Size                               | 2.9773         |\n",
    "| Health Insurance                          | 2.1310         |\n",
    "| Domestic Violence                         | 2.1221         |\n",
    "| Client ID                                 | 1.8260         |\n",
    "| Substance Use                             | 0.8678         |\n",
    "| HIV Status                                | 0.6988         |\n",
    "| Mental Illness                            | 0.5683         |\n",
    "| Chronic Illness                           | 0.4600         |\n",
    "| Physical Disability                       | 0.4592         |\n",
    "| Developmental Disability                  | 0.3017         |\n",
    "| Veteran Status                            | 0.1425         |\n",
    "| Race                                      | 0.0000         |\n",
    "| Gender                                    | 0.0000         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prioritize (Rank) Clients based on their Predicted Vulnerability Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few Client IDs:\n",
      " 0    723151\n",
      "1    721310\n",
      "2    721408\n",
      "3    721493\n",
      "4    720468\n",
      "5    631503\n",
      "6    627234\n",
      "7    610441\n",
      "8    719317\n",
      "9    716657\n",
      "Name: Client ID, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Ensure Client IDs maintain intact for the ranked output \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file ensuring Client ID is read as a string\n",
    "df = pd.read_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\", dtype={'Client ID': str})\n",
    "\n",
    "# Convert Client ID to string (in case it was misread)\n",
    "df['Client ID'] = df['Client ID'].astype(str)\n",
    "\n",
    "# Check the first few entries to ensure they are correctly formatted\n",
    "print(\"First few Client IDs:\\n\", df['Client ID'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Prob_Class_0  Prob_Class_1  Prob_Class_2 Client ID  True_Label  \\\n",
      "600           0.0          1.00          0.00    723008           1   \n",
      "171           0.0          1.00          0.00    681041           1   \n",
      "67            0.0          1.00          0.00    544579           1   \n",
      "433           0.0          1.00          0.00    522405           1   \n",
      "807           0.0          0.99          0.01    538630           1   \n",
      "\n",
      "     Vulnerability_Score  \n",
      "600                 1.00  \n",
      "171                 1.00  \n",
      "67                  1.00  \n",
      "433                 1.00  \n",
      "807                 0.99  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the original dataset to get Client IDs\n",
    "df = pd.read_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\", dtype={'Client ID': str})\n",
    "\n",
    "# Preprocess data as before\n",
    "# Assuming X_train, X_test, y_train, y_test are already prepared\n",
    "\n",
    "# Add Client IDs to X_test\n",
    "X_test_with_ids = X_test.copy()\n",
    "X_test_with_ids['Client ID'] = df.loc[X_test.index, 'Client ID']\n",
    "\n",
    "# Predict probabilities for each class\n",
    "probabilities = rf_classifier.predict_proba(X_test)\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "prob_df = pd.DataFrame(probabilities, columns=[f'Prob_Class_{i}' for i in range(probabilities.shape[1])])\n",
    "\n",
    "# Add Client IDs and target variable to the DataFrame\n",
    "prob_df['Client ID'] = X_test_with_ids['Client ID'].values\n",
    "prob_df['True_Label'] = y_test.values\n",
    "\n",
    "# Use probability of class 1 (Highly Vulnerable) for the vulnerability score\n",
    "prob_df['Vulnerability_Score'] = prob_df[f'Prob_Class_1']\n",
    "\n",
    "# Rank Client IDs based on the vulnerability score (highly vulnerable clients at the top)\n",
    "ranked_clients = prob_df.sort_values(by='Vulnerability_Score', ascending=False)\n",
    "\n",
    "# Save the ranked clients to a CSV file\n",
    "ranked_clients.to_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\ranked_clients.csv\", index=False)\n",
    "\n",
    "# Print first few rows to check the result\n",
    "print(ranked_clients.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Predicted Probabilities Output Columns\n",
    "####  View Full Predicted Probabilities Ranking Output in ranked_clients.csv file.\n",
    "\n",
    "| Column Name             | Description                                                         |\n",
    "|--------------------------|---------------------------------------------------------------------|\n",
    "| `Prob_Class_0`           | Probability of the client being classified as Class 0 (Less Vulnerable). |\n",
    "| `Prob_Class_1`           | Probability of the client being classified as Class 1 (Highly Vulnerable). |\n",
    "| `Prob_Class_2`           | Probability of the client being classified as Class 2 (Moderately Vulnerable). |\n",
    "| `Client ID`              | Unique identifier for the client. Represents the client’s ID from the dataset. |\n",
    "| `True_Label`             | Actual label of the client, indicating their true class.            |\n",
    "| `Vulnerability_Score`    | Calculated score based on the probability of being in Class 1 (Highly Vulnerable). Clients with higher scores are ranked as more vulnerable. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Filter out clients without an exit destination for more focused prioritization. \n",
    "####  View Full Predicited Probabilities Ranking Output in filtered_ranked_clients.csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Prob_Class_0  Prob_Class_1  Prob_Class_2 Client ID  True_Label  \\\n",
      "20           0.0          0.98          0.02    734308           1   \n",
      "24           0.0          0.97          0.03    538169           1   \n",
      "25           0.0          0.97          0.03    725757           1   \n",
      "29           0.0          0.97          0.03    526230           1   \n",
      "30           0.0          0.97          0.03    575911           1   \n",
      "\n",
      "    Vulnerability_Score Original Exit Destination  \n",
      "20                 0.98                       NaN  \n",
      "24                 0.97                       NaN  \n",
      "25                 0.97                       NaN  \n",
      "29                 0.97                       NaN  \n",
      "30                 0.97                       NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the original dataset to get Client IDs and exit destinations\n",
    "df = pd.read_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\CE_APR_combined.csv\", dtype={'Client ID': str})\n",
    "\n",
    "# Preprocess data as before\n",
    "# Assuming X_train, X_test, y_train, y_test, and rf_classifier are already prepared\n",
    "\n",
    "# Add Client IDs to X_test\n",
    "X_test_with_ids = X_test.copy()\n",
    "X_test_with_ids['Client ID'] = df.loc[X_test.index, 'Client ID']\n",
    "\n",
    "# Predict probabilities for each class\n",
    "probabilities = rf_classifier.predict_proba(X_test)\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "prob_df = pd.DataFrame(probabilities, columns=[f'Prob_Class_{i}' for i in range(probabilities.shape[1])])\n",
    "\n",
    "# Add Client IDs and target variable to the DataFrame\n",
    "prob_df['Client ID'] = X_test_with_ids['Client ID'].values\n",
    "prob_df['True_Label'] = y_test.values\n",
    "\n",
    "# Use probability of class 1 (Highly Vulnerable) for the vulnerability score\n",
    "prob_df['Vulnerability_Score'] = prob_df[f'Prob_Class_1']\n",
    "\n",
    "# Rank Client IDs based on the vulnerability score (highly vulnerable clients at the top)\n",
    "ranked_clients = prob_df.sort_values(by='Vulnerability_Score', ascending=False)\n",
    "\n",
    "# Filter out clients that have exit destinations\n",
    "# Ensure you merge with the original DataFrame to check for exit destinations\n",
    "ranked_clients_with_data = ranked_clients.merge(df[['Client ID', 'Original Exit Destination']], on='Client ID', how='left')\n",
    "filtered_ranked_clients = ranked_clients_with_data[ranked_clients_with_data['Original Exit Destination'].isna()]\n",
    "\n",
    "# Save the filtered ranked clients to a CSV file\n",
    "filtered_ranked_clients.to_csv(r\"C:\\Users\\desir\\vulnerabilitydetermination\\filtered_ranked_clients.csv\", index=False)\n",
    "\n",
    "# Print first few rows to check the result\n",
    "print(filtered_ranked_clients.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
